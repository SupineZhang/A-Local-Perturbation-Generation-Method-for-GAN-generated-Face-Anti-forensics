# A-Local-Perturbation-Generation-Method-for-GAN-generated-Face-Anti-forensics

## Overview
In this paper, an effective local perturbations generation method is proposed to expose the vulnerability of the state-of-art forensic detectors. The main idea is to mine the fake faces’ areas of common concern in multiple-detectors’ decision making and generate local anti-forensics noises by generative adversarial networks (GANs) in these areas to enhance the visual quality and transferability of anti-forensic faces. Meanwhile, in order to improve the anti-forensic effect, a double mask (soft mask and hard mask) strategy and a three-part loss (the GAN training loss, the adversarial loss between joint output space and feature space and the regularization loss) are designed for the training of the generator. Experiments conducted on fake faces generated by StyleGAN demonstrate the advantage of the proposed method over the state-of-art methods in terms of anti-forensics success rate, imperceptibility, and transferability.

## Prerequisites
NVIDIA GPU+CUDA CuDNN (CPU mode may also work, but untested);
Install Torch1.8 and dependencies

## Training and Test Details
Dataset: StyleGAN, CelebA;
Please adjust the file location before training and testing;
train: Change and Run the main.py;
test: Change and Run the test.py.

## Acknowledgements
This work is based on AdvGAN and its implementation:https://github.com/mathcbc/advGAN_pytorch.
